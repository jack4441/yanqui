<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="es"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>KafkaApplication.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">kafka</a> &gt; <a href="index.source.html" class="el_package">com.microservice.kafka</a> &gt; <span class="el_source">KafkaApplication.java</span></div><h1>KafkaApplication.java</h1><pre class="source lang-java linenums">package com.microservice.kafka;

import java.time.Duration;
import java.util.Arrays;
import java.util.function.Supplier;
import java.util.stream.Stream;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.serialization.Serde;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StoreQueryParameters;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.Grouped;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.state.QueryableStoreType;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.context.event.ApplicationStartedEvent;
import org.springframework.context.annotation.Bean;
import org.springframework.context.event.EventListener;
import org.springframework.kafka.annotation.EnableKafkaStreams;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.config.StreamsBuilderFactoryBean;
import org.springframework.kafka.config.TopicBuilder;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RestController;

import com.github.javafaker.Faker;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import reactor.core.publisher.Flux;

@SpringBootApplication
//@EnableKafkaStreams
<span class="fc" id="L50">public class KafkaApplication {</span>

	public static void main(String[] args) {
<span class="nc" id="L53">		SpringApplication.run(KafkaApplication.class, args);</span>
<span class="nc" id="L54">	}</span>
	
	/*@RequiredArgsConstructor
	@Component
	class Producer{
		private final KafkaTemplate&lt;Integer, String&gt; template;
		Faker faker;
		
		@EventListener(ApplicationStartedEvent.class)
		public void generate() {
			faker = Faker.instance();
			final Flux&lt;Long&gt; interval = Flux.interval(Duration.ofMillis(1_000));
			
			final Flux&lt;String&gt; quotes = Flux.fromStream(Stream.generate(new Supplier&lt;String&gt;() {
				@Override
				public String get() {
					// TODO Auto-generated method stub
					return faker.hobbit().quote();
				}
			}));
			
			Flux.zip(interval, quotes)
				.map(it -&gt; template.send(&quot;hobbit&quot;, faker.random().nextInt(42), it.getT2())).blockLast();
		}
		
	}*/
	
	/*@Component
	class Consumer{
		
		@KafkaListener(topics={&quot;streams-wordcount-output&quot;}, groupId=&quot;spring-boot-kafka&quot;)
		public void consume(ConsumerRecord&lt;String, Long&gt; record)
		{
			System.out.println(&quot;received = &quot; + record.value() + &quot; con key &quot; + record.key());
		}
	}*/
	
	//Creando topics(temas)
	@Bean
	NewTopic transferWallet() {
<span class="fc" id="L94">		return TopicBuilder.name(&quot;transferWallet&quot;).partitions(15).replicas(3).build();</span>
	}
	
	@Bean
	NewTopic detailclient() {
<span class="fc" id="L99">		return TopicBuilder.name(&quot;detailclient&quot;).partitions(15).replicas(3).build();</span>
	}
	
	@Bean
	NewTopic client() {
<span class="fc" id="L104">		return TopicBuilder.name(&quot;client&quot;).partitions(15).replicas(3).build();</span>
	}
	
	@Bean
	NewTopic product() {
<span class="fc" id="L109">		return TopicBuilder.name(&quot;product&quot;).partitions(15).replicas(3).build();</span>
	}
	
	@Bean
	NewTopic movements() {
<span class="fc" id="L114">		return TopicBuilder.name(&quot;movements&quot;).partitions(15).replicas(3).build();</span>
	}
	
	@Bean
	NewTopic hobbit2() {
<span class="fc" id="L119">		return TopicBuilder.name(&quot;hobbit2&quot;).partitions(15).replicas(3).build();</span>
	}
	
	@Bean
	NewTopic counts()
	{
<span class="fc" id="L125">		return TopicBuilder.name(&quot;streams-wordcount-output&quot;).partitions(6).replicas(3).build();</span>
	}
	
	/*@Component
	class Processor
	{
		
		@Autowired
		public void process(StreamsBuilder builder)
		{
			
			final Serde&lt;Integer&gt; integerSerde = Serdes.Integer();
			final Serde&lt;String&gt; stringSerde = Serdes.String();
			final Serde&lt;Long&gt; longSerde = Serdes.Long();
			
			KStream&lt;Integer, String&gt; textLines = builder
					.stream(&quot;hobbit&quot;, Consumed.with(integerSerde, stringSerde));
			
			KTable&lt;String, Long&gt; wordCounts = textLines
					.flatMapValues(value -&gt; Arrays.asList(value.toLowerCase().split(&quot;\\W+&quot;)))
					.groupBy((key, value) -&gt; value, Grouped.with(stringSerde, stringSerde))
					.count(Materialized.as(&quot;counts&quot;));
			
			wordCounts.toStream().to(&quot;streams-wordcount-output&quot;, Produced.with(stringSerde, longSerde));
						
		}
		
	}*/
	
	/*@RestController
	@RequiredArgsConstructor
	class RestService
	{
		private final KafkaTemplate&lt;Integer, String&gt; template;
		private final StreamsBuilderFactoryBean factoryBean;
		
		@GetMapping(&quot;/count/{word}&quot;)
		public Long getCount(@PathVariable String word)
		{
			final KafkaStreams kafkaStreams = factoryBean.getKafkaStreams();
			final ReadOnlyKeyValueStore&lt;String, Long&gt; counts = kafkaStreams
					.store(StoreQueryParameters.fromNameAndType(&quot;counts&quot;, QueryableStoreTypes.keyValueStore()));
			return counts.get(word);
		}
		
		@GetMapping(&quot;/publish/{message}&quot;)
		public void publish(@PathVariable String message)
		{
			log.info(&quot;metodo publish: &quot;+message);

			template.send(&quot;streams-wordcount-output&quot;, 45, message);
		}
		
	}*/	

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.6.202009150832</span></div></body></html>